{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Toronto neighborhood data, a Wikipedia page: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M exists that has all the information we need to explore and cluster the neighborhoods in Toronto. We will have to scrape the Wikipedia page and wrangle the data, clean it, and then read it into a pandas dataframe so that it is in a structured format.\n",
    "\n",
    "Once the data is in a structured format, we can start the analysis to explore and cluster the neighborhoods in the city of Toronto.\n",
    "\n",
    "We build the code to scrape the following Wikipedia page, https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M, in order to obtain the data that is in the table of postal codes and to transform the data into a pandas dataframe.\n",
    "\n",
    "The dataframe will consist of three columns: PostalCode, Borough, and Neighborhood. We only process the cells that have an assigned borough. We ignore cells with a borough that is Not assigned. More than one neighborhood can exist in one postal code area. For example, in the table on the Wikipedia page, you will notice that M5A is listed twice and has two neighborhoods: Harbourfront and Regent Park. These two rows will be combined into one row with the neighborhoods separated with a comma. If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough. So for the 9th cell in the table on the Wikipedia page, the value of the Borough and the Neighborhood columns will be Queen's Park.\n",
    "\n",
    "There are different website scraping libraries and packages in Python. One of the most common packages is BeautifulSoup and we will use it in this project. Package's main documentation page: http://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BeautifulSoup4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 11.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>=1.2 (from BeautifulSoup4)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/cf/ea245e52f55823f19992447b008bcbb7f78efc5960d77f6c34b5b45b36dd/soupsieve-2.0-py2.py3-none-any.whl\n",
      "Installing collected packages: soupsieve, BeautifulSoup4\n",
      "Successfully installed BeautifulSoup4-4.8.2 soupsieve-2.0\n",
      "Collecting lxml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/ba/a0e6866057fc0bbd17192925c1d63a3b85cf522965de9bc02364d08e5b84/lxml-4.5.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8MB 6.6MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.5.0\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# List of dependencies that we will need\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "import pandas as pd # library for data analsysis\n",
    "import requests # library to handle requests\n",
    "!pip install BeautifulSoup4 # Python package for using BeautifulSoup4\n",
    "!pip install --upgrade lxml # Python package for using LXML\n",
    "from bs4 import BeautifulSoup # library for pulling data out of HTML and XML files\n",
    "import lxml # Pythonic binding for the C libraries libxml2 and libxslt\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data and parse it:\n",
    "r = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M') \n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "table=soup.find('table', attrs={'class':'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get headers:\n",
    "headers=table.findAll('th')\n",
    "for i, head in enumerate(headers): headers[i]=str(headers[i]).replace(\"<th>\",\"\").replace(\"</th>\",\"\").replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all items and skip first one:\n",
    "rows=table.findAll('tr')\n",
    "rows=rows[1:len(rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip all meta symbols and line feeds between rows:\n",
    "for i, row in enumerate(rows): rows[i] = str(rows[i]).replace(\"\\n</td></tr>\",\"\").replace(\"<tr>\\n<td>\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe, expand rows and drop the old one:\n",
    "df=pd.DataFrame(rows)\n",
    "df[headers] = df[0].str.split(\"</td>\\n<td>\", n = 2, expand = True) \n",
    "df.drop(columns=[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip not assigned boroughs:\n",
    "df = df.drop(df[(df.Borough == \"Not assigned\")].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give \"Not assigned\" Neighborhoods same name as Borough:\n",
    "df.Neighbourhood.replace(\"Not assigned\", df.Borough, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy Borough value to Neighborhood if NaN:\n",
    "df.Neighbourhood.fillna(df.Borough, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows:\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract titles from columns:\n",
    "df.update(\n",
    "    df.Neighbourhood.loc[\n",
    "        lambda x: x.str.contains('title')\n",
    "    ].str.extract('title=\\\"([^\\\"]*)',expand=False))\n",
    "\n",
    "df.update(\n",
    "    df.Borough.loc[\n",
    "        lambda x: x.str.contains('title')\n",
    "    ].str.extract('title=\\\"([^\\\"]*)',expand=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete Toronto annotation from Neighbourhood:\n",
    "df.update(\n",
    "    df.Neighbourhood.loc[\n",
    "        lambda x: x.str.contains('Toronto')\n",
    "    ].str.replace(\", Toronto\",\"\"))\n",
    "df.update(\n",
    "    df.Neighbourhood.loc[\n",
    "        lambda x: x.str.contains('Toronto')\n",
    "    ].str.replace(\"\\(Toronto\\)\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Postcode        object\n",
       "Borough         object\n",
       "Neighborhood    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine multiple neighborhoods with the same post code:\n",
    "df2 = pd.DataFrame({'Postcode':df.Postcode.unique()})\n",
    "df2['Borough']=pd.DataFrame(list(set(df['Borough'].loc[df['Postcode'] == x['Postcode']])) for i, x in df2.iterrows())\n",
    "df2['Neighborhood']=pd.Series(list(set(df['Neighbourhood'].loc[df['Postcode'] == x['Postcode']])) for i, x in df2.iterrows())\n",
    "df2['Neighborhood']=df2['Neighborhood'].apply(lambda x: ', '.join(x))\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M3A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Parkwoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M4A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Victoria Village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M5A</td>\n",
       "      <td>Downtown Toronto</td>\n",
       "      <td>Regent Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M6A</td>\n",
       "      <td>North York</td>\n",
       "      <td>Lawrence Manor, Lawrence Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M7A</td>\n",
       "      <td>Downtown Toronto</td>\n",
       "      <td>Queen's Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M9A</td>\n",
       "      <td>Etobicoke</td>\n",
       "      <td>Islington Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M1B</td>\n",
       "      <td>Scarborough, Toronto</td>\n",
       "      <td>Malvern, Rouge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M3B</td>\n",
       "      <td>North York</td>\n",
       "      <td>Don Mills North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M4B</td>\n",
       "      <td>East York</td>\n",
       "      <td>Woodbine Gardens, Parkview Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M5B</td>\n",
       "      <td>Downtown Toronto</td>\n",
       "      <td>Ryerson, Garden District</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Postcode               Borough                      Neighborhood\n",
       "0      M3A            North York                         Parkwoods\n",
       "1      M4A            North York                  Victoria Village\n",
       "2      M5A      Downtown Toronto                       Regent Park\n",
       "3      M6A            North York  Lawrence Manor, Lawrence Heights\n",
       "4      M7A      Downtown Toronto                     Queen's Park \n",
       "5      M9A             Etobicoke                  Islington Avenue\n",
       "6      M1B  Scarborough, Toronto                    Malvern, Rouge\n",
       "7      M3B            North York                   Don Mills North\n",
       "8      M4B             East York   Woodbine Gardens, Parkview Hill\n",
       "9      M5B      Downtown Toronto          Ryerson, Garden District"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dataframe to csv-file:\n",
    "df2.to_csv(r'Neighborhood_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding number of raws\n",
    "df2_shape = df2.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of raws (Using .shape method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raws =  103\n"
     ]
    }
   ],
   "source": [
    "print('Number of raws = ',df2_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
